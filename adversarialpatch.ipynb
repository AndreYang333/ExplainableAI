{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPCtc5QVoFmwDIkb/tEnE8I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreYang333/ExplainableAI/blob/main/adversarialpatch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDenCilX3098",
        "outputId": "c65b8e94-5a78-4df3-f13c-408920e8ac80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraies\n",
        "!pip install torch torchvision numpy matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2HNQjrwEmwXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import torchvision.transforms.functional as F\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "BAyskdWS4EWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained ResNet34 model\n",
        "model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "model.eval()  # Set model to evaluation mode\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsBN_qrz4MlD",
        "outputId": "094a73d1-434c-4f16-f7a6-8bc9273f3901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 108MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (5): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define Transformation\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Load train dataset\n",
        "trainset = torchvision.datasets.STL10(root='./data', split='train', download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Load test dataset\n",
        "testset = torchvision.datasets.STL10(root='./data', split='test', download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Convert test dataset to a list of samples for splitting\n",
        "test_data = [(img, label) for img, label in testset]\n",
        "\n",
        "# Split test data: Move 6000 samples to train set\n",
        "train_data_from_test, remaining_test_data = train_test_split(test_data, test_size=0.25, shuffle=True)\n",
        "\n",
        "# Combine trainset with additional training data from testset\n",
        "train_data_combined = list(trainset) + train_data_from_test\n",
        "\n",
        "# Recreate trainloader and testloader with updated data\n",
        "trainloader = DataLoader(train_data_combined, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(remaining_test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# print shape of images and size of dataset\n",
        "images, labels = next(iter(trainloader))\n",
        "print(f\"New Train Image batch shape: {images.shape}\")\n",
        "print(f\"New Train dataset size: {len(train_data_combined)}\")\n",
        "\n",
        "images, labels = next(iter(testloader))\n",
        "print(f\"New Test Image batch shape: {images.shape}\")\n",
        "print(f\"New Test dataset size: {len(remaining_test_data)}\")\n"
      ],
      "metadata": {
        "id": "xc01-eyM4Ng1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680ed7b6-892b-443c-d404-5031d2b61409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2640397119/2640397119 [01:45<00:00, 24939174.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/stl10_binary.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "New Train Image batch shape: torch.Size([64, 3, 96, 96])\n",
            "New Train dataset size: 11000\n",
            "New Test Image batch shape: torch.Size([64, 3, 96, 96])\n",
            "New Test dataset size: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Assignment_data/imagenet_classes.txt') as f:\n",
        "    class_names = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Select a target class\n",
        "target_class_name = 'banana'\n",
        "target_class_index = class_names.index(target_class_name)\n",
        "print(f\"Target Class Index for '{target_class_name}': {target_class_index}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5znNd9l_nUYZ",
        "outputId": "ed79a43e-afb1-48d4-d32c-04290cc153db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Class Index for 'banana': 954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply patch to the image at a random location with random rotation\n",
        "def apply_patch(image, patch):\n",
        "    \"\"\"\n",
        "    Applies the adversarial patch to the image at a random location with random rotation.\n",
        "    \"\"\"\n",
        "    image = image.clone()\n",
        "    _, img_height, img_width = image.shape\n",
        "    patch_height, patch_width = patch.shape[1], patch.shape[2]\n",
        "\n",
        "    # Random rotation angle between 0 and 360 degrees\n",
        "    rotation_angle = np.random.uniform(0, 360)\n",
        "\n",
        "    # Rotate the image and patch randomly\n",
        "    rotated_image = F.rotate(image, rotation_angle)\n",
        "    rotated_patch = F.rotate(patch, rotation_angle)\n",
        "\n",
        "    # Ensure patch fits within the image after rotation\n",
        "    patch_height, patch_width = rotated_patch.shape[1], rotated_patch.shape[2]\n",
        "\n",
        "    # Random position for the patch\n",
        "    x_pos = np.random.randint(0, img_width - patch_width)\n",
        "    y_pos = np.random.randint(0, img_height - patch_height)\n",
        "\n",
        "    # Apply the patch to the rotated image\n",
        "    rotated_image[:, y_pos:y_pos+patch_height, x_pos:x_pos+patch_width] = rotated_patch\n",
        "\n",
        "    return rotated_image"
      ],
      "metadata": {
        "id": "BuDqBrWBna7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = (3, 10, 10)\n",
        "\n",
        "# Initialize patch\n",
        "adversarial_patch = torch.rand(*patch_size, requires_grad=True)\n",
        "\n",
        "# Ensure value is in [0,1]\n",
        "adversarial_patch.data.clamp_(0, 1)\n",
        "\n",
        "# print the shape of patch\n",
        "print(f\"Adversarial patch shape: {adversarial_patch.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDgQeW4snbe_",
        "outputId": "f154f13a-65a4-4b34-b9bd-1baa40944609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial patch shape: torch.Size([3, 10, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use Adam optimizer with learning rate and weight decay\n",
        "optimizer = optim.Adam([adversarial_patch], lr=0.01)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XeH3e_6kncjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store training, test loss values, and parameters\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "saved_params = []  # List to store the parameters of the model and adversarial patch\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    batch_count = 0\n",
        "\n",
        "    # Training phase\n",
        "    model.train()  # Set the model to training mode\n",
        "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
        "        for images, _ in tepoch:\n",
        "            tepoch.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "            images = images.clone()\n",
        "\n",
        "            # Apply the patch to each image in the batch\n",
        "            patched_images = torch.stack([apply_patch(img, adversarial_patch) for img in images])\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(patched_images)\n",
        "\n",
        "            # Create target labels (all as the target class)\n",
        "            target_labels = torch.full((images.size(0),), target_class_index, dtype=torch.long)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, target_labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Clamp patch values to [0,1]\n",
        "            adversarial_patch.data.clamp_(0, 1)\n",
        "\n",
        "            # Accumulate loss for the current batch\n",
        "            epoch_loss += loss.item()\n",
        "            batch_count += 1\n",
        "\n",
        "            # Display the loss for the current batch\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Calculate average training loss for the epoch\n",
        "    avg_train_loss = epoch_loss / batch_count\n",
        "    train_loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Save model parameters and adversarial_patch for each epoch\n",
        "    model_params = {name: param.clone() for name, param in model.named_parameters()}  # Save model parameters\n",
        "    saved_params.append({\n",
        "        'epoch': epoch + 1,\n",
        "        'model_params': model_params,\n",
        "        'adversarial_patch': adversarial_patch.clone()\n",
        "    })\n",
        "\n",
        "    # Evaluation phase (Test loss calculation)\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    test_batch_count = 0\n",
        "\n",
        "    # Turn off gradient computation during evaluation\n",
        "    with torch.no_grad():\n",
        "        with tqdm(testloader, unit=\"batch\") as tepoch:\n",
        "            for images, _ in tepoch:\n",
        "                tepoch.set_description(f\"Evaluating Test Set (Epoch {epoch+1})\")\n",
        "\n",
        "                images = images.clone()\n",
        "\n",
        "                # Apply the patch to each test image in the batch\n",
        "                patched_images = torch.stack([apply_patch(img, adversarial_patch) for img in images])\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(patched_images)\n",
        "\n",
        "                # Create target labels (all as the target class)\n",
        "                target_labels = torch.full((images.size(0),), target_class_index, dtype=torch.long)\n",
        "\n",
        "                # Compute test loss\n",
        "                loss = criterion(outputs, target_labels)\n",
        "\n",
        "                # Accumulate the test loss\n",
        "                test_loss += loss.item()\n",
        "                test_batch_count += 1\n",
        "\n",
        "                tepoch.set_postfix(test_loss=loss.item())\n",
        "\n",
        "    # Calculate average test loss for the epoch\n",
        "    avg_test_loss = test_loss / test_batch_count\n",
        "    test_loss_values.append(avg_test_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Test Loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "# Plot training and test loss over epochs\n",
        "plt.plot(train_loss_values, label='Training Loss', marker='o')\n",
        "plt.plot(test_loss_values, label='Test Loss', marker='x')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUNTLqganggH",
        "outputId": "4cc7cd81-c506-4288-acdf-017b988ffd38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15:  28%|██▊       | 48/172 [05:20<13:48,  6.68s/batch, loss=11.7]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Evaluate the patch\n",
        "model.eval()\n",
        "success = 0\n",
        "total = 0\n",
        "\n",
        "for images, labels in testloader:\n",
        "    images = images.clone()\n",
        "    patched_image = apply_patch(images[0], adversarial_patch)\n",
        "    patched_image = patched_image.unsqueeze(0)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(patched_image)\n",
        "    _, predicted = outputs.max(1)\n",
        "\n",
        "    total += 1\n",
        "    if predicted.item() == target_class_index:\n",
        "        success += 1\n",
        "\n",
        "print(f\"Attack Success Rate: {100 * success / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "RlhqK_7Ynkjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert patch tensor to PIL Image for visualization\n",
        "def tensor_to_pil(tensor):\n",
        "    tensor = tensor.detach().cpu()\n",
        "    tensor = transforms.ToPILImage()(tensor)\n",
        "    return tensor\n",
        "\n",
        "patch_image = tensor_to_pil(adversarial_patch)\n",
        "plt.imshow(patch_image)\n",
        "plt.title(\"Adversarial Patch\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bQm6Gv78nlyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a sample patched image\n",
        "sample_image, _ = next(iter(testloader))\n",
        "patched_sample = apply_patch(sample_image[0], adversarial_patch)\n",
        "patched_sample = patched_sample.unsqueeze(0)\n",
        "\n",
        "# Get model prediction\n",
        "outputs = model(patched_sample)\n",
        "_, predicted = outputs.max(1)\n",
        "predicted_class = class_names[predicted.item()]\n",
        "\n",
        "# Display the image\n",
        "patched_sample_image = tensor_to_pil(patched_sample[0])\n",
        "plt.imshow(patched_sample_image)\n",
        "plt.title(f\"Predicted Class: {predicted_class}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IbgwXhJvnm3S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}