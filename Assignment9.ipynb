{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMyjfKYcEQ+Nrk/XVCfj1+A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreYang333/ExplainableAI/blob/main/Assignment9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 9\n",
        "## Minjie Yang(my189)\n",
        "Link to reference code:https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Main_Demo.ipynb#scrollTo=GGO1aY4gILpn\n",
        "Link to github:https://github.com/AndreYang333/ExplainableAI.git"
      ],
      "metadata": {
        "id": "iW0XKilFgJAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries"
      ],
      "metadata": {
        "id": "cEXIjBdlgXnX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0rkh6d9Snj7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "DEVELOPMENT_MODE = False\n",
        "# Detect if we're running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Install if in Colab\n",
        "if IN_COLAB:\n",
        "    %pip install transformer_lens\n",
        "    %pip install circuitsvis\n",
        "    # Install a faster Node version\n",
        "    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs  # noqa\n",
        "\n",
        "# Hot reload in development mode & not running on the CD\n",
        "if not IN_COLAB:\n",
        "    from IPython import get_ipython\n",
        "    ip = get_ipython()\n",
        "    if not ip.extension_manager.loaded:\n",
        "        ip.extension_manager.load('autoreload')\n",
        "        %autoreload 2\n",
        "\n",
        "IN_GITHUB = os.getenv(\"GITHUB_ACTIONS\") == \"true\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import tqdm.auto as tqdm\n",
        "import plotly.express as px\n",
        "\n",
        "from jaxtyping import Float\n",
        "from functools import partial\n",
        "\n",
        "# import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, FactoredMatrix"
      ],
      "metadata": {
        "id": "JXF03NNRSw3A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."
      ],
      "metadata": {
        "id": "i7Xql_DXg6O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_grad_enabled(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_KRLTXiTdLR",
        "outputId": "02c5d014-a5cf-420d-c289-3ef5d856141b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7fabee297d00>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = utils.get_device()\n",
        "# NBVAL_IGNORE_OUTPUT\n",
        "model = HookedTransformer.from_pretrained(\"EleutherAI/gpt-neo-125M\", device=device)"
      ],
      "metadata": {
        "id": "8PgoEy4TTguv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_description_text = \"\"\"## Loading Models\n",
        "\n",
        "HookedTransformer comes loaded with >40 open source GPT-style models. You can load any of them in with `HookedTransformer.from_pretrained(MODEL_NAME)`. See my explainer for documentation of all supported models, and this table for hyper-parameters and the name used to load them. Each model is loaded into the consistent HookedTransformer architecture, designed to be clean, consistent and interpretability-friendly.\n",
        "\n",
        "For this demo notebook we'll look at GPT-Neo 125M\"\"\"\n",
        "loss = model(model_description_text, return_type=\"loss\")\n",
        "print(\"Model loss:\", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "supYlwa0TkUH",
        "outputId": "be92872c-7a64-4f8b-de55-b6a50543fd26"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loss: tensor(3.9140, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis example"
      ],
      "metadata": {
        "id": "vJy5yVXkXuAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define clean and corrupted prompts\n",
        "clean_prompt = \"The movie was amazing, with a captivating storyline and brilliant acting. Please return answer in positive or negative.This review is\"\n",
        "corrupted_prompt = \"The movie was dreadful, with a boring plot and poor acting. Please return answer in positive or negative.This review is\"\n",
        "\n",
        "clean_tokens = model.to_tokens(clean_prompt)\n",
        "corrupted_tokens = model.to_tokens(corrupted_prompt)\n",
        "\n",
        "# Function to calculate the difference between the logits of the correct and incorrect answers\n",
        "def logits_to_logit_diff(logits, correct_answer=\" positive\", incorrect_answer=\" negative\"):\n",
        "    # model.to_single_token maps a string representing a single token to its token index\n",
        "    # If the string is not a single token, this function will raise an error\n",
        "    correct_index = model.to_single_token(correct_answer)\n",
        "    incorrect_index = model.to_single_token(incorrect_answer)\n",
        "\n",
        "    # Calculate and return the logit difference\n",
        "    return logits[0, -1, correct_index] - logits[0, -1, incorrect_index]\n",
        "\n",
        "# Run the model on the clean prompt and cache activations\n",
        "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
        "clean_logit_diff = logits_to_logit_diff(clean_logits, \" positive\", \" negative\")\n",
        "print(f\"Logit difference for the clean prompt: {clean_logit_diff.item():.3f}\")\n",
        "\n",
        "# Run the model on the corrupted prompt\n",
        "corrupted_logits = model(corrupted_tokens)\n",
        "corrupted_logit_diff = logits_to_logit_diff(corrupted_logits, \" positive\", \" negative\")\n",
        "print(f\"Logit difference for the corrupted prompt: {corrupted_logit_diff.item():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsV8iyDIUJdR",
        "outputId": "7f842c96-aa41-4b4f-b699-a3221c15f35a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logit difference for the clean prompt: 0.946\n",
            "Logit difference for the corrupted prompt: 0.549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis of the Results\n",
        "\n",
        "1. **Logit Difference for the Clean Prompt: 0.946**\n",
        "   - The difference of 0.946 suggests that the model strongly believes the review is positive.\n",
        "   - **Interpretation**: This result is expected since the clean prompt clearly conveys positive sentiment.\n",
        "\n",
        "2. **Logit Difference for the Corrupted Prompt: 0.549**\n",
        "   - Despite the corrupted prompt describing negative sentiment, the model leans toward the \"positive\" answer, though with lower confidence compared to the clean prompt.\n",
        "   - **Interpretation**: The result indicates that the model struggles to fully recognize the negative sentiment in the corrupted prompt. It may suggest that the model has a bias toward positive predictions, potentially due to its pretraining on text data that favors positive language. Alternatively, it could indicate that the wording in the prompt does not strongly convey negative sentiment.\n"
      ],
      "metadata": {
        "id": "zOItlsgVY4pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define clean and corrupted prompts with clearer and stronger sentiment cues\n",
        "clean_prompt = \"You are an helpful assistant to determine following review is positive or negative. The movie was absolutely phenomenal, with an engaging storyline and outstanding performances. This review is\"\n",
        "corrupted_prompt = \"You are an helpful assistant to determine following review is positive or negative. The movie was extremely disappointing, with a tedious plot and terrible acting. This review is\"\n",
        "\n",
        "clean_tokens = model.to_tokens(clean_prompt)\n",
        "corrupted_tokens = model.to_tokens(corrupted_prompt)\n",
        "\n",
        "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
        "clean_logit_diff = logits_to_logit_diff(clean_logits, \" positive\", \" negative\")\n",
        "print(f\"Logit difference for the clean prompt: {clean_logit_diff.item():.3f}\")\n",
        "\n",
        "corrupted_logits = model(corrupted_tokens)\n",
        "corrupted_logit_diff = logits_to_logit_diff(corrupted_logits, \" positive\", \" negative\")\n",
        "print(f\"Logit difference for the corrupted prompt: {corrupted_logit_diff.item():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3067F_zU7rY",
        "outputId": "604c0027-ef90-4f8b-d410-865e69e19af7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logit difference for the clean prompt: 2.794\n",
            "Logit difference for the corrupted prompt: 1.224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Comparative Insights\n",
        "1. **Increased Confidence for Both Prompts**: The modified prompts resulted in higher logit differences for both the clean and corrupted prompts. This indicates that the modifications made the sentiment cues clearer and more impactful, leading to a stronger model response.\n",
        "2. **Persistent Bias**: Despite the clearer language and explicit instruction, the model still shows a tendency to favor the \"positive\" label, even for the corrupted prompt. The difference is less pronounced than in the original prompts but still suggests an underlying bias or an insufficient sensitivity to negative sentiment.\n"
      ],
      "metadata": {
        "id": "eh994yY_bMnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define clean and corrupted prompts\n",
        "clean_prompt = \"You are an helpful assistant to determine following review is positive or negative. The movie was absolutely phenomenal, with an engaging storyline and outstanding performances. This review is\"\n",
        "corrupted_prompt = \"You are an helpful assistant to determine following review is positive or negative. The movie was extremely disappointing, with a tedious plot and terrible acting. This review is\"\n",
        "\n",
        "# Function to calculate cross-entropy loss for the correct label\n",
        "def calculate_cross_entropy_loss(logits, correct_answer=\" positive\"):\n",
        "    # Get the token index for the correct answer\n",
        "    correct_index = model.to_single_token(correct_answer)\n",
        "    target_tensor = torch.tensor([correct_index], device=logits.device)\n",
        "\n",
        "    # Take the logits for the last token and add a batch dimension\n",
        "    logits_final = logits[0, -1, :].unsqueeze(0)\n",
        "\n",
        "    # Calculate and return cross-entropy loss\n",
        "    loss = F.cross_entropy(logits_final, target_tensor)\n",
        "    return loss\n",
        "\n",
        "# Run the model on the clean prompt and compute cross-entropy loss\n",
        "clean_logits, _ = model.run_with_cache(clean_tokens)\n",
        "clean_loss = calculate_cross_entropy_loss(clean_logits, \" positive\")\n",
        "print(f\"Cross-entropy loss for the clean prompt: {clean_loss.item():.3f}\")\n",
        "\n",
        "# Run the model on the corrupted prompt and compute cross-entropy loss\n",
        "corrupted_logits = model(corrupted_tokens)\n",
        "corrupted_loss = calculate_cross_entropy_loss(corrupted_logits, \" negative\")\n",
        "print(f\"Cross-entropy loss for the corrupted prompt: {corrupted_loss.item():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hMz9iDjaNSe",
        "outputId": "f206459e-c8d5-4fe1-9742-6829494fca19"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-entropy loss for the clean prompt: 4.708\n",
            "Cross-entropy loss for the corrupted prompt: 6.320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparative Analysis Between Logit Difference and Cross-Entropy Loss\n",
        "\n",
        "### 1. Results Recap\n",
        "#### Using Logit Difference\n",
        "- **Clean Prompt**: Logit difference = 2.794\n",
        "- **Corrupted Prompt**: Logit difference = 1.224\n",
        "  \n",
        "#### Using Cross-Entropy Loss\n",
        "- **Clean Prompt**: Cross-entropy loss = 4.708\n",
        "- **Corrupted Prompt**: Cross-entropy loss = 6.320\n",
        "  - **Interpretation**: The cross-entropy loss values were relatively high for both prompts, suggesting that the model had significant uncertainty in both cases. The loss was even higher for the corrupted prompt, indicating greater difficulty in classifying negative sentiment.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Comparative Insights\n",
        "\n",
        "  **Sensitivity to Sentiment**:\n",
        "   - The **logit difference method** suggests that the model does respond differently to positive and negative prompts, but not as strongly as desired.\n",
        "   - The **cross-entropy loss method** makes it clearer that the model is much less certain when dealing with negative sentiment, highlighting a potential area for improvement.\n",
        "\n",
        "---\n",
        "\n",
        "### Recommendations\n",
        "**Model Improvement**: To address the issues highlighted by both methods, consider fine-tuning the model on a more balanced dataset that includes a wide variety of positive and negative examples.\n"
      ],
      "metadata": {
        "id": "3vE5bE_rc17u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IOI task"
      ],
      "metadata": {
        "id": "yRSOHNEydk7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the clean and corrupted prompts for possessive pronoun identification\n",
        "clean_prompt = \"Andre and Jason are playing basketball. Andre took a step and got past\"\n",
        "corrupted_prompt = \"Andre and Jason are playing basketball. Jason took a step and got past\"\n",
        "\n",
        "clean_tokens = model.to_tokens(clean_prompt)\n",
        "corrupted_tokens = model.to_tokens(corrupted_prompt)\n",
        "\n",
        "# Function to calculate the difference between the logits of the correct and incorrect answers\n",
        "def logits_to_logit_diff(logits, correct_answer=\" Jason\", incorrect_answer=\" Andre\"):\n",
        "    # model.to_single_token maps a string value of a single token to the token index for that token\n",
        "    # If the string is not a single token, it raises an error.\n",
        "    correct_index = model.to_single_token(correct_answer)\n",
        "    incorrect_index = model.to_single_token(incorrect_answer)\n",
        "    return logits[0, -1, correct_index] - logits[0, -1, incorrect_index]\n",
        "\n",
        "# Run the model on the clean prompt and store activations\n",
        "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
        "clean_logit_diff = logits_to_logit_diff(clean_logits)\n",
        "print(f\"Clean logit difference: {clean_logit_diff.item():.3f}\")\n",
        "\n",
        "# Run the model on the corrupted prompt without caching activations\n",
        "corrupted_logits = model(corrupted_tokens)\n",
        "corrupted_logit_diff = logits_to_logit_diff(corrupted_logits)\n",
        "print(f\"Corrupted logit difference: {corrupted_logit_diff.item():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaJIxlVwbwSv",
        "outputId": "cdabf853-1af9-46b9-a45c-7496a753df14"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean logit difference: 4.440\n",
            "Corrupted logit difference: -0.567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis of the Results\n",
        "\n",
        "1. **Clean Logit Difference: 4.440**\n",
        "   - This is expected because the context clearly implies that Andre successfully got past Jason while playing basketball, making \"Jason\" the natural choice for the last word.\n",
        "   - **Interpretation**: The model understands the narrative flow of the clean sentence and confidently chooses \"Jason\" as the correct continuation, suggesting a good grasp of the context and possessive pronoun implications.\n",
        "\n",
        "2. **Corrupted Logit Difference: -0.567**\n",
        "   - This is logical because the corrupted prompt introduces a semantic inconsistency: it implies that Jason got past someone, but the prior context suggests that Andre is the one who should be getting past Jason.\n",
        "   - **Interpretation**:This suggests that the model recognizes something is off but may not fully understand how to resolve the confusion.\n"
      ],
      "metadata": {
        "id": "l5S_72NIfOU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate cross-entropy loss for the correct label\n",
        "def calculate_cross_entropy_loss(logits, correct_answer):\n",
        "    # Get the token index for the correct answer\n",
        "    correct_index = model.to_single_token(correct_answer)\n",
        "    target_tensor = torch.tensor([correct_index], device=logits.device)  # Move target tensor to the same device as logits\n",
        "\n",
        "    # Take the logits for the last token and add a batch dimension\n",
        "    logits_final = logits[0, -1, :].unsqueeze(0)\n",
        "\n",
        "    # Calculate and return cross-entropy loss\n",
        "    loss = F.cross_entropy(logits_final, target_tensor)\n",
        "    return loss\n",
        "\n",
        "# Run the model on the clean prompt and compute cross-entropy loss\n",
        "clean_logits, _ = model.run_with_cache(clean_tokens)\n",
        "clean_loss = calculate_cross_entropy_loss(clean_logits, \" Jason\")\n",
        "print(f\"Cross-entropy loss for the clean prompt: {clean_loss.item():.3f}\")\n",
        "\n",
        "# Run the model on the corrupted prompt and compute cross-entropy loss\n",
        "corrupted_logits = model(corrupted_tokens)\n",
        "corrupted_loss = calculate_cross_entropy_loss(corrupted_logits, \" Andre\")\n",
        "print(f\"Cross-entropy loss for the corrupted prompt: {corrupted_loss.item():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OtIMopQdjcO",
        "outputId": "f5274fe1-3280-4ef4-b3ab-cfccdcb69c1a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-entropy loss for the clean prompt: 2.334\n",
            "Cross-entropy loss for the corrupted prompt: 4.496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- The model is more confident when the prompt makes logical sense (lower loss for the clean prompt) and less confident when the prompt introduces a semantic inconsistency (higher loss for the corrupted prompt).\n",
        "- **Key Insight**: The increase in cross-entropy loss from the clean to the corrupted prompt demonstrates that the model is sensitive to changes in context and logical flow, but it still struggles with fully resolving inconsistencies, as indicated by the relatively high loss for the corrupted prompt."
      ],
      "metadata": {
        "id": "-e_aHowMf9KO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nh9iFuPMfrz4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}